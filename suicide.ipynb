{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJET: DETECTION DE TWEET A CARACTERE SUICIDAIRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de se projet est de développer un algorithme capable de prédire des tweets suicidaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = pd.read_csv('/home/paul/Projets/Datasets/suicide/Suicide_Ideation_Dataset(Twitter-based).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Tweet                  Suicide\n",
      "0                                  making some lunch         Not Suicide post\n",
      "1                        @Alexia You want his money.         Not Suicide post\n",
      "2  @dizzyhrvy that crap took me forever to put to...  Potential Suicide post \n",
      "3  @jnaylor #kiwitweets Hey Jer! Since when did y...         Not Suicide post\n",
      "4  Trying out &quot;Delicious Library 2&quot; wit...         Not Suicide post\n",
      "5  @ValenValdez Oh, that's good to hear. But is i...         Not Suicide post\n",
      "6  @mcm180 u've got a list for fellow #hotties? Y...         Not Suicide post\n",
      "7  @jakepaul @jamescharles @LoganPaul Just becaus...  Potential Suicide post \n",
      "8          time for some warsaw beer garden chilling         Not Suicide post\n",
      "9  I hate my life lmao I hope I die soon or sumn ...  Potential Suicide post \n"
     ]
    }
   ],
   "source": [
    "print(tweet.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not Suicide post', 'Potential Suicide post '], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.Suicide.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet['Tweet'] = tweet['Tweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet['label'] = tweet['Suicide'].map({'Not Suicide post':0,\"Potential Suicide post \":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "1782    0\n",
      "1783    0\n",
      "1784    0\n",
      "1785    0\n",
      "1786    0\n",
      "Name: label, Length: 1787, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweet['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suicide\n",
       "Not Suicide post           1127\n",
       "Potential Suicide post      660\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet['Suicide'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet      2\n",
       "Suicide    0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet      2\n",
       "Suicide    0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweet.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet      0\n",
       "Suicide    0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppression des caractères inutiles et de la ponctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Test***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am free '"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"[^\\w\\s]\"\n",
    "\n",
    "text = \"I am free #.\"\n",
    "\n",
    "re.sub(pattern, \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_no_word(text):\n",
    "\n",
    "    pattern = r\"[^\\w\\s]\"\n",
    "\n",
    "    return re.sub(pattern, \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet['Tweet_clean'] = tweet['Tweet'].apply(remove_no_word)\n",
    "\n",
    "tweet['Tweet_clean'] = tweet['Tweet_clean'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                       making some lunch\n",
      "1                               alexia you want his money\n",
      "2       dizzyhrvy that crap took me forever to put tog...\n",
      "3       jnaylor kiwitweets hey jer since when did you ...\n",
      "4       trying out quotdelicious library 2quot with mi...\n",
      "                              ...                        \n",
      "1782       i have forgotten how much i love my nokia n951\n",
      "1783    starting my day out with a positive attitude t...\n",
      "1784    belledame222 hey its 5 amgive a girl some cred...\n",
      "1785    2 drunken besties stumble into my room and we ...\n",
      "1786    dancingbonita quoti friggin love youquot ron b...\n",
      "Name: Tweet_clean, Length: 1785, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(tweet['Tweet_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization, suppression des stops words et lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokanize_stop_word_lemmatize(text):\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    return [word.lemma_ for word in doc if not word.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet['Tweet_clean'] = tweet['Tweet_clean'].apply(tokanize_stop_word_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['make', 'lunch']\n"
     ]
    }
   ],
   "source": [
    "print(tweet['Tweet_clean'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(text):\n",
    "\n",
    "    doc = nlp(\" \".join(text))\n",
    "\n",
    "    return doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(tweet['Tweet_clean'][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet['Tweet_clean'] = tweet['Tweet_clean'].apply(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [-3.364215, 1.01506, -0.6452, -3.24055, 1.2228...\n",
      "1       [0.051306564, 2.21501, -4.7852464, -0.50859994...\n",
      "2       [1.0736338, 1.7380373, -3.4406252, -0.31427503...\n",
      "3       [0.7017867, 0.46629003, -0.220475, 0.38841334,...\n",
      "4       [1.0777183, 1.4754522, -0.45207277, 0.8051967,...\n",
      "                              ...                        \n",
      "1782    [0.69080245, -0.311, -1.6120825, -2.5361698, -...\n",
      "1783    [0.34875855, 1.8456343, -2.3566685, -0.61416, ...\n",
      "1784    [1.1211486, -1.4620672, -2.6991572, -0.2523457...\n",
      "1785    [0.41769776, -1.4369525, -0.38016158, 2.233723...\n",
      "1786    [-0.030727778, 0.15775912, -1.76967, -1.003467...\n",
      "Name: Tweet_clean, Length: 1785, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(tweet['Tweet_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "# 2. Entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.stack(tweet.Tweet_clean.values), tweet.label, train_size= 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Modèle 1: Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "model1 = XGBClassifier()\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy: {model1.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grille de recherche des meilleurs hyperparametres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur modèle: {'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 300} <-> Score de validation: 0.8823530855109801 <-> Score sur le train: 0.9187675070028011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model1 = XGBClassifier()\n",
    "\n",
    "grille_param = {'n_estimators': [300], 'learning_rate': [0.01,0.1], 'max_depth': [5,10], 'min_child_weight': [1]}\n",
    "\n",
    "grille = GridSearchCV(model1, param_grid= grille_param, cv = 5)\n",
    "\n",
    "grille.fit(X_train, y_train)\n",
    "\n",
    "model1_best = grille.best_estimator_\n",
    "\n",
    "model1_best.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Meilleur modèle: {grille.best_params_} <-> Score de validation: {grille.best_score_} <-> Score sur le train: {model1_best.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métriques avancées**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "      Not Suicide post       0.92      0.96      0.94       229\n",
      "Potential Suicide post       0.92      0.84      0.88       128\n",
      "\n",
      "              accuracy                           0.92       357\n",
      "             macro avg       0.92      0.90      0.91       357\n",
      "          weighted avg       0.92      0.92      0.92       357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1_best.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names= ['Not Suicide post',\"Potential Suicide post\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple de prédiction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential Suicide post\n"
     ]
    }
   ],
   "source": [
    "def predict_suicide(text):\n",
    "\n",
    "    doc = remove_no_word(text)\n",
    "\n",
    "    doc = tokanize_stop_word_lemmatize(text)\n",
    "\n",
    "    doc = embedding(doc)\n",
    "\n",
    "    result = (model1_best.predict(doc.reshape(1,-1)))\n",
    "\n",
    "    if result == 0:\n",
    "\n",
    "        print(\"Not suicide post\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"Potential Suicide post\")\n",
    "\n",
    "\n",
    "predict_suicide(\"I tired of this life\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Modèle 1: Les machines à vecteurs supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9159663865546218"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = SVC(kernel= 'rbf', C= 2)\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "model1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suicide post\n"
     ]
    }
   ],
   "source": [
    "def predict_suicide(text):\n",
    "\n",
    "    doc = remove_no_word(text)\n",
    "\n",
    "    doc = tokanize_stop_word_lemmatize(text)\n",
    "\n",
    "    doc = embedding(doc)\n",
    "\n",
    "    result = (model1.predict(doc.reshape(1,-1)))\n",
    "\n",
    "    if result == 0:\n",
    "\n",
    "        print(\"Not suicide post\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"Suicide post\")\n",
    "\n",
    "\n",
    "predict_suicide(\"I'm tired of this life\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
